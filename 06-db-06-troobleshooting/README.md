# Домашнее задание к занятию "6.6. Troubleshooting"

---
## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя

Необходимо с помощью $currentOp вычислить ID зависшей операции CRUD
```
db.getSiblingDB("admin").aggregate( [
    { $currentOp : { allUsers: true, localOps: true } },
    { $match : <filter condition> } // Optional.  Specify the condition to find the op.
                                   // e.g. { op: "getmore", "command.collection": "someCollection" }
] )
```
Затем, с мопощью  db.killOp() необходимо "убить" зависшую операцию
```
db.killOp(<opid of the query to kill>)
```
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

1. Можно рекомендовать пользователю при выполнении своих запросов применять метод maxTimeMS() и указывать в милисекундах время через которое повисший запрос будет прерван.
```
# Пример выполнения запроса с методом maxTimeMS()
db.collection.find({description: /August [0-9]+, 1969/}).maxTimeMS(50)
```
2. Необходимо проанализировать производительность запроса пользователя методомами db.collection.explain(“executionStats”) и cursor.explain(“executionStats”). На основе полученных данных необходимо грамотно настроить индексы, для используемых в запросе полей, для коллекции к которой обращается пользователь. Если пользователь своим запросом читает данные из коллекции - стоит добавить индекы для нужных полей данных, если записывает или меняет данные - возможно, в коллекции уже слишком много индексов и какие-то мало-используемые нужно удалить.
```
# Добавляем индексы
db.collection.createIndex(
  <key and index type specification>,
  <options>
)

# Просматриваем уже имеющиеся индексы
db.collection.getIndexes();

# Удаляем лишние индексы
db.collection.dropIndexes()
```
3. Причиной низкой производительности запросов могут быть блокировки, возможно необходимо оптимизировать сам запрос.
4. Так же не стоит исключать возможных проблем с дифицитом ресурсов железа. Необходимо проанализировать нагрузку на ЦПУ, ОЗУ, дисковую подсистему.

---
## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим

Ключи с истекшим TTL перестали удаляться.

- Redis блокирует операции записи

На хосте закончилась выделенная для Redis память. Redis возвращает ошибку, потому что для вставки данных недостаточно памяти.

Как вы думаете, в чем может быть проблема?

Пользователи стали создавать очень много новых ключей, а механизм активного удаления истекших ключей не успевает удалять старые ключи в нужном количестве и Redis блокирует запись новых ключей, пока не будет завершена ресурсоемкая операция активного удаления истекших ключей.

Возможное решение проблемы - изменение стратегии удаления ключей из памяти.

---
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

Скорее всего это происходит, потому что очень большое колическтво строк отправляется как часть одного или нескольких запросов пользователя. В этом случае необходимо  увеличить значение системной переменной net_read_timeout, она регулирует время в течении которого клиент может производить чтение с сервера, после чего соединение обрывается.

Так же это могло произойти, потому что у клиента не получается установить начальное соединение с сервером. Что бы проверить эту версию необходимо воспользоваться  SHOW GLOBAL STATUS LIKE 'Aborted_connects', если данный счетчик увеличивается при появлянии ошибки у пользователя, значит это наш случай и нам необходимо увеличить значение системной переменной connect_timeout, которая регулирует время ожидания сервером подключения клиента. 

Так же данная ошибка может происходить потому, что значение используемых BLOB-объектов больше значения заданного в переменной max_allowed_packet, которая отвечает за максимальный размер одного пересылаемого пакета. Данную переменную следует увеличивать если пользователи используют большие BLOB-колонки или длинные строки. 

---
## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Данное сообщение говорит о том, что Linux запустил процесс Out-Of-Memory Killer, процесс который завершает приложение, чтобы спасти ядро ОС от сбоя. Это происходит потому, что процессы запущенные на хостовой ОС исчерпали ресурсы оперативной памяти, и функция select_bad_process() выбрала процесс postgres наилучшим кандидатом для остановки, что бы решить проблемы ядра ОС с нехваткой оперативной памяти. При этом, все существующие подключения к БД продолжают нормально функционировать, а новые соединения установить не получится. Для нормальной работы PostgreSQL его необходимо перезагрузить.

Как бы вы решили данную проблему?

1. Во первых, необходимо проанализировать, что происходит с оперативной памятью на ОС. Возможно, памяти слишком мало, тогда следует физически увеличить количество ОЗУ; возможно, параллельно с postgres в операционной системе работают другие требольтельные к ОЗУ процессы, тогда postgres лучше запустить на отдельной машине; возможно, postgres запущен в системе виртуализации и гипервизор не выделяет ОС с postgres  достаточное количество памяти, тогда следует изменить настройки виртуальной машины и увеличить количество выделяемой памяти.

2. Так же можно попробовать изменить параметр ядра Linux, переменную vm.overcommit_memory.
```
sysctl -w vm.overcommit_memory=2
```
При таком значении переменной, ядро не будет резервировать больше памяти, чем указано в параметре overcommit_ratio (в котором указывается процент памяти, для которого допустимо избыточное резервирование). Т.е. для всех запускаемых в ОС процессов ядро будет резирвировать ограниченное количество памяти, что снизит вероятность исчерпания ОЗУ и вызова процесса Out-Of-Memory Killer 

3. Ещё вариант решения данной проблемы: изменить параметр ядра oom_score_adj, который отвечает за приоритетность уничтожения каждого процесса OOM-Killer-ом. Выставив большое отрицательное значение для службы postgres мы сильно снизим вероятность того, что Out-Of-Memory Killer "нападет" именно на наш процесс.

Чтобы задать значение oom_score_adj, необходимо установить OOMScoreAdjust в блоке сервиса: 
```
[Service]
OOMScoreAdjust=-1000
```
---
